const OB = {
  "s1_title": "Meet PocketLLM",
  "s1_sub": "One chat interface. Multiple LLMs. Smart routing, tools, and memory—under your control.",
  "s1_cta": "Continue",
  "s1_skip": "Skip setup",
  "s2_title": "Connect your LLM providers",
  "s2_sub": "Use OpenAI, Groq, Gemini, or local (Ollama). Your keys stay private—you decide what’s stored.",
  "s2_cta": "Connect providers",
  "s2_later": "I’ll do this later",
  "s2_chips": "OpenAI,Groq,Gemini,Ollama (Local),Anthropic",
  "s3_title": "Smart routing. Tool use. Memory.",
  "s3_sub": "PocketLLM picks the best model per task and can use tools (search, code, RAG). Toggle features now.",
  "s3_toggles": "Enable smart routing,Allow tool use (web/code/RAG),Conversation memory",
  "s3_cta": "Continue",
  "s4_title": "Your data, your rules",
  "s4_sub": "Choose where to store history and embeddings. You can change this anytime in Settings.",
  "s4_checks": "Store chat history locally only,Sync anonymized usage analytics,Enable local vector cache for RAG",
  "s4_cta": "Continue",
  "s5_title": "Quick actions & notifications",
  "s5_sub": "Enable notifications and clipboard access for faster replies and 'Share to PocketLLM.'",
  "s5_cta": "Enable",
  "s5_skip": "Not now",
  "s6_title": "You’re set",
  "s6_sub": "Start your first chat or import previous conversations.",
  "s6_cta": "Start chatting",
  "s6_alt": "Import history"
};
